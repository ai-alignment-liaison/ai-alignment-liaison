{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jG1G6dSfAkC6",
    "outputId": "fd60df33-5cbd-4fa8-8bec-9ce7f8f12f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.47.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZzuNd5as7d1B"
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J7hBBjMH2oxX"
   },
   "outputs": [],
   "source": [
    "fairness_values = []\n",
    "equal_treatment_value = \"\"\"**Equal Treatment**\n",
    "This principle asserts that AI systems should not favor or disadvantage any user or group based on protected characteristics such as race, gender, age, or religion. This requires careful design and testing to ensure that AI systems do not unintentionally reproduce existing biases in their decisions or behavior.\"\"\"\n",
    "\n",
    "bias_mitigation_value = \"\"\"**Bias Mitigation:***\n",
    "This principle involves actively working to identify and minimize biases in AI systems. This can include biases in the data used to train the system, biases in the design of the system itself, or biases in how the system is deployed or used. Bias mitigation might involve techniques such as debiasing algorithms, fairness metrics, and rigorous testing for bias.\"\"\"\n",
    "\n",
    "fairness_values.append(equal_treatment_value)\n",
    "fairness_values.append(bias_mitigation_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ue0M4eWe_j_N"
   },
   "outputs": [],
   "source": [
    "accountability_values = []\n",
    "impact_assessment_value = \"\"\"**Impact Assessment:**\n",
    "Impact assessment refers to evaluating the potential effects of an AI system before it is deployed, as well as monitoring its impact once it is in use. This can help to identify potential risks and benefits, inform design and deployment decisions, and provide evidence of the system's impacts.\"\"\"\n",
    "\n",
    "auditability_value = \"\"\"**Auditability:**\n",
    "Auditability involves designing AI systems in such a way that their decisions and behavior can be inspected and reviewed. This can involve keeping detailed logs of the system's operation, as well as using interpretable models or explanation techniques. Auditability can help to ensure accountability by making it possible to investigate and understand the AI system's actions.\"\"\"\n",
    "\n",
    "reporting_documentation_value = \"\"\"**Reporting and Documentation:**\n",
    "Reporting and documentation involve keeping detailed records of the design, development, and deployment of AI systems. This can include documenting the algorithms used, the data sources, the design decisions, the testing procedures, and the impact assessments. Good documentation can support accountability by providing evidence of the steps taken to ensure ethical AI.\"\"\"\n",
    "\n",
    "accountability_values.append(impact_assessment_value)\n",
    "accountability_values.append(auditability_value)\n",
    "accountability_values.append(reporting_documentation_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p-KjSh9IABhc"
   },
   "outputs": [],
   "source": [
    "human_values = {}\n",
    "human_values['fairness'] = fairness_values\n",
    "human_values['accountability'] = accountability_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hf4B9NaxFsPi"
   },
   "outputs": [],
   "source": [
    "organization_context = \"\"\"The AI Alignment Liaison is designed to guide organizations in aligning AI product development processes with specific values or objectives, ensuring that AI systems reflect responsible practices. The system collects extensive context from the organization, using this information to help teams identify, prioritize, and act upon core values. It facilitates deriving responsible AI product requirements from these values by providing structured processes and tools.\n",
    "\n",
    "One key feature is the human-in-the-loop approach, where the system does not make decisions but helps users define, prioritize, and meet their values. The system integrates with existing tools and supports the automation of tasks (with user consent), such as generating documentation, suggesting validation strategies, and monitoring the progress of responsible AI goals.\n",
    "\n",
    "The project-driven context retrieval pipeline collects and organizes relevant information from the organization's files and activities. The system provides a traceability tool from values through requirements to actions and validation methods, providing a comprehensive view of the AI alignment process.\n",
    "\n",
    "The AI Alignment Liaison also helps with compliance with regulatory standards like GDPR, EU AI Act, and the New York City Automated Employment Decision Tools Law by collaborating with the user to develop product requirements (for a given product), develop action strategies to meet those product requirements, and develop validation strategies to validate that the requirements are satisfied.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLINuylw2oub",
    "outputId": "ce193a3c-594f-4e5b-96d5-7aec85aaa6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Product Requirements Derived from the Human Value of **Equal Treatment**\n",
      "\n",
      "1. **Bias Detection and Mitigation Tools**\n",
      "   - **Requirement:** Implement automated tools to detect and flag potential biases in AI models and datasets.\n",
      "   - **Description:** The system should include algorithms and processes to identify biases related to protected characteristics (e.g., race, gender, age, religion) in training data and model outputs.\n",
      "   - **Priority:** High\n",
      "\n",
      "2. **Diverse Data Collection and Curation**\n",
      "   - **Requirement:** Ensure that training datasets are representative of diverse populations.\n",
      "   - **Description:** The system should guide users in collecting and curating datasets that include a balanced representation of different demographic groups to prevent skewed AI behavior.\n",
      "   - **Priority:** High\n",
      "\n",
      "3. **Fairness Audits and Reporting**\n",
      "   - **Requirement:** Provide tools for conducting regular fairness audits and generating comprehensive reports.\n",
      "   - **Description:** The system should facilitate periodic audits of AI systems to assess their fairness and generate reports that document findings and corrective actions taken.\n",
      "   - **Priority:** Medium\n",
      "\n",
      "4. **Human-in-the-Loop Validation**\n",
      "   - **Requirement:** Incorporate human oversight in the validation of AI systems to ensure equal treatment.\n",
      "   - **Description:** The system should enable human\n",
      "\n",
      "---\n",
      "\n",
      "### Product Requirements for Bias Mitigation\n",
      "\n",
      "1. **Bias Identification and Analysis Tools**\n",
      "   - **Requirement:** Develop and integrate tools that can automatically identify and analyze potential biases in datasets, algorithms, and AI models.\n",
      "   - **Rationale:** To ensure that biases are detected early in the development process, allowing for timely intervention and correction.\n",
      "\n",
      "2. **Debiasing Algorithms**\n",
      "   - **Requirement:** Implement and provide access to state-of-the-art debiasing algorithms that can be applied to datasets and models.\n",
      "   - **Rationale:** To actively reduce biases in the data and models, ensuring fairer outcomes.\n",
      "\n",
      "3. **Fairness Metrics and Reporting**\n",
      "   - **Requirement:** Incorporate fairness metrics that can be used to evaluate the performance of AI systems with respect to bias. Generate regular reports on these metrics.\n",
      "   - **Rationale:** To provide quantifiable measures of bias and track improvements over time.\n",
      "\n",
      "4. **Bias Testing Framework**\n",
      "   - **Requirement:** Develop a rigorous testing framework that includes various scenarios and edge cases to test for biases in AI systems.\n",
      "   - **Rationale:** To ensure comprehensive evaluation of AI systems for biases before deployment.\n",
      "\n",
      "5. **Human-in-the-Loop Bias Review**\n",
      "   - **Requirement:** Facilitate a human-in-the\n",
      "\n",
      "---\n",
      "\n",
      "### Product Requirements Derived from the Human Value: Impact Assessment\n",
      "\n",
      "1. **Impact Assessment Framework Integration**\n",
      "   - **Requirement:** The system must include a comprehensive impact assessment framework that guides users through evaluating potential effects of AI systems before deployment and during their operational lifecycle.\n",
      "   - **Rationale:** To ensure that potential risks and benefits are identified and managed effectively.\n",
      "\n",
      "2. **Pre-Deployment Impact Evaluation**\n",
      "   - **Requirement:** The system must provide tools and templates for conducting thorough pre-deployment impact evaluations, including risk assessment, benefit analysis, and stakeholder impact analysis.\n",
      "   - **Rationale:** To inform design and deployment decisions with a clear understanding of potential impacts.\n",
      "\n",
      "3. **Continuous Monitoring and Reporting**\n",
      "   - **Requirement:** The system must support continuous monitoring of AI systems post-deployment, with automated data collection and reporting features to track ongoing impacts.\n",
      "   - **Rationale:** To provide evidence of the system's impacts and ensure ongoing alignment with responsible practices.\n",
      "\n",
      "4. **Stakeholder Involvement Tools**\n",
      "   - **Requirement:** The system must include features that facilitate stakeholder involvement in the impact assessment process, such as feedback collection, surveys, and collaborative review tools.\n",
      "   - **Rationale:** To ensure diverse perspectives are considered and to enhance the legitimacy and comprehensiveness\n",
      "\n",
      "---\n",
      "\n",
      "### Product Requirements Derived from the Value of Auditability\n",
      "\n",
      "1. **Detailed Logging Mechanism**\n",
      "   - **Requirement:** Implement a comprehensive logging system that records all significant actions, decisions, and changes made by the AI system.\n",
      "   - **Description:** The system should capture detailed logs, including input data, decision-making processes, and output results. Logs should be timestamped and securely stored to ensure integrity and availability for future audits.\n",
      "\n",
      "2. **Interpretable Models and Explanation Techniques**\n",
      "   - **Requirement:** Integrate interpretable models and explanation techniques to provide clear, understandable insights into the AI system's decision-making process.\n",
      "   - **Description:** Use models that are inherently interpretable or apply post-hoc explanation methods (e.g., LIME, SHAP) to complex models. Ensure that explanations are accessible to non-technical stakeholders.\n",
      "\n",
      "3. **Traceability Tool**\n",
      "   - **Requirement:** Develop and maintain a traceability tool that links values, requirements, actions, and validation methods.\n",
      "   - **Description:** The tool should provide a clear, navigable path from organizational values to specific AI system requirements, the actions taken to meet those requirements, and the methods used to validate them. This ensures that every decision can be traced back to its origin.\n",
      "\n",
      "4. **\n",
      "\n",
      "---\n",
      "\n",
      "### Product Requirements Derived from the Human Value: Reporting and Documentation\n",
      "\n",
      "1. **Comprehensive Documentation Generation**\n",
      "   - **Requirement:** The system must generate detailed documentation for each stage of the AI product lifecycle, including design, development, and deployment phases.\n",
      "   - **Details:** This documentation should cover algorithms used, data sources, design decisions, testing procedures, and impact assessments.\n",
      "\n",
      "2. **Automated Documentation Tools**\n",
      "   - **Requirement:** The system should provide tools to automate the generation of documentation, with user consent.\n",
      "   - **Details:** These tools should be capable of extracting relevant information from the organization's files and activities to create comprehensive reports.\n",
      "\n",
      "3. **Traceability and Version Control**\n",
      "   - **Requirement:** The system must include a traceability tool that links values to requirements, actions, and validation methods.\n",
      "   - **Details:** This tool should support version control to track changes over time and ensure that all documentation is up-to-date and accurate.\n",
      "\n",
      "4. **User-Friendly Reporting Interface**\n",
      "   - **Requirement:** The system should offer a user-friendly interface for creating, viewing, and managing documentation.\n",
      "   - **Details:** The interface should allow users to easily navigate through different sections of the documentation and make updates as needed.\n",
      "\n",
      "5. **Compliance Documentation**\n",
      "   - **Requirement\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def derive_product_requirements(project_description, human_value):\n",
    "    \"\"\"\n",
    "    Uses GPT-4o to derive product requirements given a human value.\n",
    "\n",
    "    Args:\n",
    "      human_value: A string describing a human value.\n",
    "\n",
    "    Returns:\n",
    "      A string containing the derived product requirements.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"This is the product I am working on:\n",
    "    {project_description}\n",
    "\n",
    "    Please derive product requirements from the following human value:\n",
    "\n",
    "    {human_value}\n",
    "\n",
    "    Provide the requirements in a clear and concise manner within a product development context.\n",
    "    \"\"\"\n",
    "\n",
    "    client = openai.OpenAI(\n",
    "        api_key=\"\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "               model=\"gpt-4o\",\n",
    "               messages=[\n",
    "                  {\"role\": \"system\", \"content\": \"You are a helpful assistant that derives product requirements from human values.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}\n",
    "               ]\n",
    "               )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "               model=\"gpt-4o\",\n",
    "               messages=[\n",
    "                  {\"role\": \"system\", \"content\": \"You are a helpful assistant that derives product requirements from human values.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}\n",
    "               ],\n",
    "               temperature=0,\n",
    "               max_tokens=256\n",
    "               )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "for value in human_values['fairness']:\n",
    "  print(derive_product_requirements(organization_context, value))\n",
    "  print(\"\\n---\\n\")\n",
    "\n",
    "for value in human_values['accountability']:\n",
    "  print(derive_product_requirements(organization_context, value))\n",
    "  print(\"\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
